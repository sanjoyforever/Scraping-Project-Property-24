{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca62fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4779a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PropertyScraper:\n",
    "    def __init__(self, transaction_type='for-sale', filename='property_data.csv'):\n",
    "        self.transaction_type = transaction_type\n",
    "        self.filename = filename\n",
    "        self.base_url = f\"https://www.property24.com/{self.transaction_type}/advanced-search/results/p2?sp=pid%3d9%2c7%2c8%2c3%2c2%2c5%2c6%2c14%2c1\"\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36'\n",
    "        }\n",
    "        self.titles = []\n",
    "        self.prices = []\n",
    "        self.links = []\n",
    "        self.areas = []\n",
    "        self.locations = []\n",
    "\n",
    "    def extract_numbers(self, text):\n",
    "        numbers = re.findall(r'\\d+', text)\n",
    "        return ''.join(numbers)\n",
    "\n",
    "    def get_last_page_number(self):\n",
    "        response = requests.get(self.base_url, headers=self.headers)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            page_no = int(soup.find('ul', class_='pagination').find_all('a')[-1].get('data-pagenumber'))\n",
    "            return page_no\n",
    "        return 0\n",
    "\n",
    "    def scrape_page(self, page_number):\n",
    "        url = f\"https://www.property24.com/{self.transaction_type}/advanced-search/results/p{page_number}?sp=pid%3d9%2c7%2c8%2c3%2c2%2c5%2c6%2c14%2c1\"\n",
    "        response = requests.get(url, headers=self.headers)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            elements = soup.find_all(class_=lambda x: x and '_tileContainer' in x)\n",
    "\n",
    "            for element in elements:\n",
    "                title = price = link = area = location = \"NA\"\n",
    "\n",
    "                if element.find('span', class_='p24_title'):\n",
    "                    title = element.find('span', class_='p24_title').text\n",
    "                    price = element.find('span', class_='p24_price').get('content')\n",
    "                if element.find('div', class_='p24_promotedTile'):\n",
    "                    title = element.find('div', class_='p24_promotedTile').get('title')\n",
    "                    price = self.extract_numbers(element.find('div', class_='p24_price').text)\n",
    "                link = \"https://property24.com\" + element.find('a').get('href')\n",
    "\n",
    "                if element.find('img', class_='p24_sizeIcon'):\n",
    "                    area = element.find('img', class_='p24_sizeIcon').find_next_sibling().text\n",
    "\n",
    "                if element.find('span', class_='p24_location'):\n",
    "                    location = element.find('span', class_='p24_location').text\n",
    "\n",
    "                self.titles.append(title)\n",
    "                self.prices.append(price)\n",
    "                self.links.append(link)\n",
    "                self.areas.append(area)\n",
    "                self.locations.append(location)\n",
    "\n",
    "    def save_data(self, filename=None):\n",
    "        if filename is None:\n",
    "            filename = self.filename\n",
    "        data = {\n",
    "            \"Title\": self.titles,\n",
    "            \"Price\": self.prices,\n",
    "            \"Area\": self.areas,\n",
    "            \"Locations\": self.locations,\n",
    "            \"Link\": self.links,\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(filename, index=False)\n",
    "\n",
    "    def run_scraper(self):\n",
    "        last_page = self.get_last_page_number()\n",
    "        for page_number in tqdm(range(1, last_page + 1)):\n",
    "            self.scrape_page(page_number)\n",
    "            if page_number % 100 == 0:\n",
    "                self.save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc16549",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    scraper = PropertyScraper(\"for-rent\", \"for_rent.csv\")\n",
    "    scraper.run_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44429fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
